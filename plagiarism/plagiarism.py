from functions import stemming,ngram,TFIDF,genlib,summary,plgcpy
import functions
import pandas as pd
import matplotlib.pyplot as plt
#%%
# Plagiarism- TASK A
inst_1='Inheritance is a basic concept of Object-Oriented Programming where the basic idea is to create new classes that add extra detail to existing classes. This is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class. Inheritance models the “is-kind-of” relationship between entities (or objects), for example, postgraduates and undergraduates are both kinds of student. This kind of relationship can be visualised as a tree structure, where ‘student’ would be the more general root node and both ‘postgraduate’ and ‘undergraduate’ would be more specialised extensions of the ‘student’ node (or the child nodes). In this relationship ‘student’ would be known as the superclass or parent class whereas, ‘postgraduate’ would be known as the subclass or child class because the ‘postgraduate’ class extends the ‘student’ class. Inheritance can occur on several layers, where if visualised would display a larger tree structure. For example, we could further extend the ‘postgraduate’ node by adding two extra extended classes to it called, ‘MSc Student’ and ‘PhD Student’ as both these types of student are kinds of postgraduate student. This would mean that both the ‘MSc Student’ and ‘PhD Student’ classes would inherit methods and variables from both the ‘postgraduate’ and ‘student classes’.'
inst_2='inheritance in object oriented programming is where a new class is formed using classes which have allready been defined. These classes have have some of the behavior and attributes which where existent in the classes that it inherited from. The peropos of inheritance in object oriented programming is to minimize the reuse of existing code without modification. Inheritance allowes classes to be categorized, similer to the way humans catagorize. It also provides a way to generalize du to the "is a" relationship between classes. For example a "cow" is a generalization of "animal" similarly so are "pigs" & cheaters". Defeining classes in this way, allows us to define attributes and behaviours which are commen to all animals in one class, so cheaters would natuarly inheart properities commen to all animals. The advantage of inheritance is that classes which would otherwise have alot of similar code , can instead shair the same code, thus reducing the complexity of the program. Inheritance, therefore, can also be refered to as polymorphism which is where many pieces of code are controled by shared control code. Inheritance can be accomplished by overriding methods in its ancestor, or by adding new methods.'
inst_3='When we talk about inheritance in object-oriented programming languages, which is a concept that was invented in 1967 for Simula, we are usually talking about a way to form new classes and classes are instances of which are called objects and involve using classes that have already been defined. Derived classes  are intended to help reuse existing code with little or no modification and  are the new classes that  take over (or inherit) attributes and behavior of the pre-existing classes, usually referred to as base classes (or ancestor classes). Categorization in computer languages is a powerful way number of processing information and inheritance provides the support for representation by categorization. Furthermore,  it is fundamental for helping humans learn by means of generalization in what is known about specific entities is applied to a wider group given a belongs relation can be established and cognitive processing which involves less information being acquired to be stored about each specific entity, but in actual fact only its particularities. An instance of a "fruit" is a generalization of "apple", "orange", "mango" and many others. Inheritance can also sometimes be referred to as generalization, because is-a relationships represent a hierarchy amongst classes of objects. It can be considered that fruit is an abstraction of apple, orange, etc. Conversely, since apples are fruit, they may naturally inherit all the properties common to all fruit, such as being a fleshy container for the seed of a plant. Modules with sufficiently similarities in interfaces would be able to share a lot of code and therefore reducing the complexity of the program. This can be known as one of the advantages of inheritance. Therefore inheritance can be known to have a further view, a dual, which describes many parts of code that are under control of shared control code, named as polymorphism. On the other hand, inheritance is normally accomplished either by replacing one or more methods exposed by ancestor, or by adding new methods to those exposed by an ancestor. A well known term used for this replacing act is called overriding.'
inst_4='Inheritance is an important feature in object orientated programming. This is because it allows new classes to be made that extend previous classes and to go into more detail. This is carried out by allowing the new class to reuse the existing class methods and variables, whilst also creating class specific methods and variables. This means that the new class, the subclass, is a more specialised version of the original, or superclass. Because of this it means that the subclass can use all the public methods and variables from the superclass; however any private methods or variables are still private. Also it should be noted that a class can only extend one class, e.g. can only be a subclass to one superclass. However a superclass can have more then one subclass and a class can both be a subclass and a superclass. If this occurs then all of the non-private methods and variables can be used by the most specialised class. This means that inheritance is used when types have common factors and these would be put into the superclass. Then the subclass/es then extend these to add more detail. An example of this could be using a superclass of employee and then to have two subclasses called fulltime and part time. As employee could have name, address and other details whilst full time could just have salary and part time could work out the salary from part time hours worked, as the full time members of staff wouldn’t need these.'
inst_5='Inheritance is a method of forming new classes using predefined classes. The new classes are called derived classes and they inherit the behaviours and attributes of the base classes. It was intended to allow existing code to be used again with minimal or no alteration. It also offers support for representation by categorization in computer languages; this is a powerful mechanism of information processing, vital to human learning by means of generalization and cognitive economy. Inheritance is occasionally referred to as generalization due to the fact that is-a relationships represent a hierarchy between classes of objects. Inheritance has the advantage of reducing the complexity of a program since modules with very similar interfaces can share lots of code. Due to this, inheritance has another view called polymorphism, where many sections of code are being controlled by some shared control code. Inheritance is normally achieved by overriding one or more methods exposed by ancestor, or by creating new methods on top of those exposed by an ancestor. Inheritance has a variety of uses. Each different use focuses on different properties, for example the external behaviour of objects, internal structure of an object, inheritance hierarchy structure, or software engineering properties of inheritance. Occasionally it is advantageous to differentiate between these uses, as it is not necessarily noticeable from context. '
inst_6='Inheritance in object oriented programming is a way to form new classes using classes that have already been defined. The new classes, known as derived classes, inherit attributes and behaviour of the existing classes, which are referred to as base classes. With little or no modification, it is intended to help reuse existing code. It is typically accomplished either by overriding one or more methods exposed by ancestor, or by adding new methods to those exposed by an ancestor. Inheritance is also sometimes called generalization, because there is-a relationships represent a hierarchy between classes of objects. A ‘fruit’, for instance, is a generalization of "orange", "mango", "apples" and many others. One can consider fruit to be an abstraction of apple, orange, etc. Since apples are fruit (i.e., an apple is-a fruit), conversely apples may naturally inherit all the properties common to all fruit, such as being a fleshy container for the seed of a plant. An advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code reducing the complexity of the program.'
inst_7='In object-oriented programming, inheritance is a way to form new classes (instances of which are called objects) using classes that have already been defined. The inheritance concept was invented in 1967 for Simula. The new classes, known as derived classes, take over (or inherit) attribute and behaviour of the pre-existing classes, which are referred to as base classes (or ancestor classes). It is intended to help reuse existing code with little or no modification. Inheritance provides the support for representation by categorization in computer languages. Categorization is a powerful mechanism number of information processing, crucial to human learning by means of generalization (what is known about specific entities is applied to a wider group given a belongs relation can be established) and cognitive economy (less information needs to be stored about each specific entity, only its particularities). Inheritance is also sometimes called generalization, because the is-a relationships represent a hierarchy between classes of objects. For instance, a "fruit" is a generalization of "apple", "orange", "mango" and many others. One can consider fruit to be an abstraction of apple, orange, etc. Conversely, since apples are fruit (i.e., an apple is-a fruit), apples may naturally inherit all the properties common to all fruit, such as being a fleshy container for the seed of a plant. An advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code, reducing the complexity of the program. Inheritance therefore has another view, a dual, called polymorphism, which describes many pieces of code being controlled by shared control code. Inheritance is typically accomplished either by overriding (replacing) one or more methods exposed by ancestor, or by adding new methods to those exposed by an ancestor.'
inst_8='Inheritance is a basic concept in object oriented programming. It models the reuse of existing class code in new classes – the “is a kind of” relationship. For example, a house is a kind of building; similarly, an office block is a kind of building. Both house and office block will inherit certain characteristics from buildings, but also have their own personal characteristics – a house may have a number of occupants, whereas an office block will have a number of offices. However, these personal characteristics dont apply to all types of buildings. In this example, the building would be considered the superclass – it contains general characteristics for other objects to inherit – and the house and office block are both subclasses – they are specific types and specialise the characteristics of the superclass. Java allows object inheritance. When one class inherits from another class, all the public variables and methods are available to the subclass. In this example, the Circle class is a subclass of the Shape class. The Shape class provides a public setColour method, which will be available to the Circle class and other subclasses of Shape. However, the private variable colour (as defined in the Shape class) will not be available for direct manipulation by the Circle class because it is not inherited. The Circle class specialises the Shape class, which means that setRadius is available to the Circle class and all subclasses of Circle, but it isnt available to the superclass Shape. '
inst_9='Object oriented programming is a style of programming that supports encapsulation, inheritance, and polymorphism. Inheritance means derived  a new class from the base class.  We can also say there are parents class and child classes in inheritance.  Inheritance was firstly derived in 1967. The child class has all the features of parents class or we can say the base class more over it may also include some additional features.  Inheritance is used for modification and implementation new features in computer programming language.It is possible that child class has all the attributes of parents class but it is not possible that all the attributes of child class must have in base class or parent class. I categorization in computer language also inheritance is a useful tool.categorization define as a powerful  feature.it  has been also used in generalisation and in human learning. In some areas less information need to be stored. Generlisation also some time known as inheritance. The main reason behind this is a hierarchi structure of objects and classes. We can understand  this mechanism by some examples: like fruit is aq main class and mangoes apple ,orange is child classs of the main class.So obviously inherit all the properties of fruit class.'
inst_10='The idea of inheritance in OOP refers to the formation of new classes with the already existing classes. The concept of inheritance was basically formulated for Simula in 1967. As a result, the newly created inherited or derived classes inherit the properties and behavior of the classes from which they are derived. These original classes are either called base classes or sometimes referred to as ancestor classes. The idea of inheritance is to reuse the existing code with little or no modification at all. The basic support provided by inheritance is that it represents by categorization in computer languages. The power mechanism number of information processing that is crucial to human learning by the means of generalization and cognitive economy is called categorization. Where generalization if the knowledge of specific entities and is applied to a wider group provided that belongs relation can be created. On the other hand cognitive economy is where less information needs to be stored about each specific entity except for some particularities. There are examples where we can have modules with similar interfaces. The advantage that inheritance provides is that it makes such modules share a lot of code which consequently reduces the complexity of the program.'
inst_11='Inheritance is a concept in Object Oriented programming where a child- or sub-class inherits characteristics from a parent- or super-class.  The concept takes its name from genetic inheritance where a child can inherit genetic characteristics from its parents. Inheritance, at its simplest, allows programmers to model a relationship where one object is a kind of another.  For instance two classes, one representing an undergraduate student and another representing a post-graduate student could both be said to belong to a more generalised class representing all students. Similarly, we could say that dogs and cats are two kinds of animal, or that bridges and skyscrapers are two types of man-made structure. Subclasses are said to extend or specialise their superclasses.  Attributes (variables) and behaviours (functions) that are common between classes can be included in the definition of the superclass, leaving the subclass definitions containing only the attributes and behaviours that are unique to that class. Inheritance can be used to create a multiple level architecture of classes.  In such an architecture even the bottom-most subclasses inherit all of the attributes and behaviours that are defined in the very top-most superclasses.  This can save the programmer time because it renders unnecessary a lot of code duplication.'
inst_12='Inheritance is a way to form new classes (instances of which are called objects) using classes that have already been defined. The new classes, known as derived classes, take over (or inherit) attributes and behavior of the pre-existing classes, which are referred to as base classes (or ancestor classes). It is intended to help reuse existing code with little or no modification. An advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code, reducing the complexity of the program. Inheritance therefore has another view, a dual, called polymorphism, which describes many pieces of code being controlled by shared control code. Inheritance is typically accomplished either by overriding (replacing) one or more methods exposed by ancestor, or by adding new methods to those exposed by an ancestor. In defining this inheritance hierarchy we have already defined certain restrictions, not all of which are desirable. Singleness: using single inheritance, a subclass can inherit from only one superclass. Visibility: whenever client code has access to an object, it generally has access to all the objects superclass data. Static: the inheritance hierarchy of an object is fixed at instantiation when the objects type is selected and does not change with time.'
inst_13='In object-oriented programming, inheritance is a way to form new classes (instances of which are called objects) using classes that have already been defined. Inheritance is also sometimes called generalization, because the is-a relationships represent a hierarchy between classes of objects. For instance, a "fruit" is a generalization of "apple", "orange", "mango" and many others. One can consider fruit to be an abstraction of apple, orange, etc. Conversely, since apples are fruit (i.e., an apple is-a fruit), apples may naturally inherit all the properties common to all ruit, such as being a fleshy container for the seed of a plant. Inheritance is typically accomplished either by overriding (replacing) one or more methods exposed by ancestor, or by adding new methods to those exposed by an ancestor.'
inst_14='Inheritance is one of the basic concepts of Object Oriented Programming.  It’s objective is to add more detail to pre-existing classes whilst still allowing the methods and variables of these classes to be reused.  The easiest way to look at inheritance is as an “…is a kind of” relationship.  For example, a guitar is a kind of string instrument, electric, acoustic and steel stringed are all types of guitar. The further down an inheritance tree you get, the more specific the classes become.  An example here would be books.  Books generally fall into two categories, fiction and non-fiction.  Each of these can then be sub-divided into more groups.  Fiction for example can be split into fantasy, horror, romance and many more.  Non-fiction splits the same way into other topics such as history, geography, cooking etc.  History of course can be sub-divided into time periods like the Romans, the Elizabethans, the World Wars and so on. '
inst_15='In object oriented programming, objects are grouped together into classes according to their type, structure and the functions that can be performed on them. Inheritance is a process in object oriented programming in which objects acquire (or inherit) the properties of objects of another class. It is therefore used to create relationships between one object and another. Each class groups together objects of a similar type, with similar properties. New classes can be formed by this process whose objects will have properties of both the classes from which this new class is formed. A superclass has all of the properties of the subclasses below it. At the same time subclasses are each distinctive from each other but related via the superclass. Subclasses are said to ‘extend’ superclasses. Due to these relationships, object oriented programmes tend to be easier to modify since they do not need to be changed when a new object, with different properties is added. Instead, a new object is made to inherit properties of objects which already exist. Inheritance can be divided into two main processes: single inheritance and multiple inheritance. Single inheritance means that the class can only inherit from one other class, whereas multiple inheritance allows for inheritance from several classes.'
inst_16='Inheritance allows programs developed in an Object Orientated language to reuse code without having it replicated unnecessarily elsewhere within the program. To achieve this, the programmer has to note generalisations and similarities about various aspects of the program. For example, a program could exist to model different forms of transport. At first glance, a car and a train may not have much in common. But abstractly, both will have a speed at which they are travelling, a direction, and a current position. Methods utilising this data can be specified high up in the inheritance hierarchy, for example in a ‘Transport’ class. For example you could have a method which works out the new position of a train after travelling x minutes in direction y. Likewise, you might want to be able to find out the same information for an object of the type car. Inheritance means that if such a method was defined in the superclass of the train and car classes, any car or train object can utilise it. The train and car subclasses are said to ‘extend’ the Transport class, as they will have additional characteristics which they don’t share. E.g. passenger capacity would be a class variable of both car and train (but have different values), and a train may have methods along the lines of ‘is toilet engaged’. If you then wanted to add additional forms of transport, such as an aeroplane, you may wish for that also to have a ‘toilet engaged’ function. Then you could have an extended hierarchy, where a Mass Transport class extends the Transport class. Under which you’d have a train and aeroplane, which would inherit characteristics from both super classes.'
inst_17='In object-oriented programming, inheritance is a way to form new classes (instances of which are called objects) using classes that have already been defined. The inheritance concept was invented in 1967 for Simula. Inheritance provides the support for representation by categorization in computer languages. Categorization is a powerful mechanism number of information processing, crucial to human learning by means of generalization and cognitive economy (less information needs to be stored about each specific entity, only its particularities). The new classes, known as derived classes, take over (or inherit) attributes and behavior of the pre-existing classes, which are referred to as base classes (or ancestor classes). It is intended to help reuse existing code with little or no modification. Inheritance is also sometimes called generalization, because the is-a relationships represent a hierarchy between classes of objects. For instance, a "fruit" is a generalization of "apple", "orange", "mango" and many others. One can consider fruit to be an abstraction of apple, orange, etc. Conversely, since apples are fruit (i.e., an apple is-a fruit), apples may naturally inherit all the properties common to all fruit, such as being a fleshy container for the seed of a plant. An advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code, reducing the complexity of the program. Inheritance therefore has another view, a dual, called polymorphism, which describes many pieces of code being controlled by shared control code. Inheritance is typically accomplished either by overriding (replacing) one or more methods exposed by ancestor, or by adding new methods to those exposed by an ancestor. Complex inheritance, or inheritance used within a design that is not sufficiently mature, may lead to the Yo-yo problem. '
inst_18='Inheritance is the ability of a subclass to inherit default, protected and public attributes and methods from its superclasses. Each object (except java.lang.Object) can be cast to an object of one of its superclasses. However an object cannot be cast to a class which is no relative of it. Here is an example of inheritance: We have the class of all living things which have attributes like weight and age. We have the classes of animals, plants, viruses and fungi that are subclasses of the class of all living things. The animals have their unique attributes (organs, hair, etc.) and methods (walking, mating, etc.). They also inherit the attributes and methods of its superclass. Animals can be treated (cast) to living things. However, animals cannot be treated as fungi. In object oriented programming inheritance is also dependant on access level modifiers. For example private attributes and methods cannot be inherited. Virtual attributes and methods can be shadowed/overridden. In Java all attributes and methods are implicitly virtual. Object variable can store a reference to the same class or a subclass (i.e. this or more specialised version). However, object variables cannot store references to a superclass (i.e. less specialised version) of the original class.'
inst_19='In object-oriented programming, inheritance is the ability to specify one class to be a subclass of another; this leads to a hierarchy of classes, with the child classes inheriting and specialising - and sometimes adding to - the functionality and data structures of the parent classes. The hierarchy that is formed is also useful for the organisation of classes and objects, as it defines a relationship between the child and the parent (the child class is a “kind of” the parent class). Inheritance is useful for situations where several classes share common features, such as needed functions or data variables. In addition to this, child classes can be referenced in terms of their parent classes, which can be useful when storing large data structures of objects of several classes, which can all be referenced as one base class. Inheritance is a core aspect of object-oriented programming, and is available in some form or another in most, if not all, object oriented languages available today. Most of these languages provide an “extend” keyword, which is used to subclass another. Also, the functions and data variables that are inherited by the subclasses can be controlled through the use of visibility modifiers.'
orig='In object-oriented programming, inheritance is a way to form new classes (instances of which are called objects) using classes that have already been defined. The inheritance concept was invented in 1967 for Simula. The new classes, known as derived classes, take over (or inherit) attributes and behavior of the pre-existing classes, which are referred to as base classes (or ancestor classes). It is intended to help reuse existing code with little or no modification. Inheritance provides the support for representation by categorization in computer languages. Categorization is a powerful mechanism number of information processing, crucial to human learning by means of generalization (what is known about specific entities is applied to a wider group given a belongs relation can be established) and cognitive economy (less information needs to be stored about each specific entity, only its particularities). Inheritance is also sometimes called generalization, because the is-a relationships represent a hierarchy between classes of objects. For instance, a "fruit" is a generalization of "apple", "orange", "mango" and many others. One can consider fruit to be an abstraction of apple, orange, etc. Conversely, since apples are fruit (i.e., an apple is-a fruit), apples may naturally inherit all the properties common to all fruit, such as being a fleshy container for the seed of a plant. An advantage of inheritance is that modules with sufficiently similar interfaces can share a lot of code, reducing the complexity of the program. Inheritance therefore has another view, a dual, called polymorphism, which describes many pieces of code being controlled by shared control code. Inheritance is typically accomplished either by overriding (replacing) one or more methods exposed by ancestor, or by adding new methods to those exposed by an ancestor. Complex inheritance, or inheritance used within a design that is not sufficiently mature, may lead to the Yo-yo problem.'
#%%
# Plagiarism- TASK B
b_1='PageRank is a link analysis algorithm used by the Google Internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents, such as the World Wide Web, with the purpose of "measuring" its relative importance within the set. Google assigns a numeric weighting from 0-10 for each webpage on the Internet; this PageRank denotes a site’s importance in the eyes of Google. The PageRank is derived from a theoretical probability value on a logarithmic scale like the Richter Scale. The PageRank? of a particular page is roughly based upon the quantity of inbound links as well as the PageRank of the pages providing the links. The algorithm may be applied to any collection of entities with reciprocal quotations and references. The numerical weight that it assigns to any given element E is also called the PageRank of E and denoted by PR(E). It is known that other factors, e.g. relevance of search words on the page and actual visits to the page reported by the Google toolbar also influence the PageRank. Other link-based ranking algorithms for Web pages include the HITS algorithm invented by Jon Kleinberg (used by Teoma and now Ask.com), the IBM CLEVER project, and the TrustRank algorithm.'
b_2='PageRank is a link analysis algorithm used by the Google Internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents, such as the World Wide Web, with the purpose of "measuring" its relative importance within the set. Google assigns a numeric weighting from 0-10 for each webpage on the Internet; this PageRank denotes a site’s importance in the eyes of Google. The PageRank is derived from a theoretical probability value on a logarithmic scale like the Richter Scale. PageRank is a probability distribution used to represent the likelihood that a person randomly clicking on links will arrive at any particular page. PageRank can be calculated for collections of documents of any size. It is assumed in several research papers that the distribution is evenly divided between all documents in the collection at the beginning of the computational process. The PageRank computations require several passes, called "iterations", through the collection to adjust approximate PageRank values to more closely reflect the theoretical true value. A probability is expressed as a numeric value between 0 and 1. A 0.5 probability is commonly expressed as a "50% chance" of something happening. Hence, a PageRank of 0.5 means there is a 50% chance that a person clicking on a random link will be directed to the document with the 0.5 PageRank. The PageRank theory holds that even an imaginary surfer who is randomly clicking on links will eventually stop clicking. The probability, at any step, that the person will continue is a damping factor d. Various studies have tested different damping factors, but it is generally assumed that the damping factor will be set around 0.85.'
b_3='PageRank is a probability distribution used to represent the likelihood that a person randomly clicking on links will arrive at any particular page. It is assumed in several research papers that the distribution is evenly divided between all documents in the collection at the beginning of the computational process. PageRank can be calculated for collections of documents of any size The PageRank computations require several passes, called "iterations", through the collection to adjust approximate PageRank values to more closely reflect the theoretical true value. A probability is expressed as a numeric value between 0 and 1. A 0. 5 probability is commonly expressed as a "50% chance" of something happening. Hence, a PageRank of 0.5 means there is a 50% chance that a person clicking on a random link will be directed to the document with the 0.5 PageRank. Simplified algorithm How PageRank Works Assume a small universe of four web pages: A, B, C and D. The initial approximation of PageRank would be evenly divided between these four documents. Hence, each document would begin with an estimated PageRank of 0.25. In the original form of PageRank initial values were simply 1. This meant that the sum of all pages was the total number of pages on the web. Later versions of PageRank (see the below formulas) would assume a probability distribution between 0 and 1. Here were going to simply use a probability distribution hence the initial value of 0.25.'
b='PageRank is a link analysis algorithm used by the Google Internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents, such as the World Wide Web, with the purpose of "measuring" its relative importance within the set. The algorithm may be applied to any collection of entities with reciprocal quotations and references. The numerical weight that it assigns to any given element E is also called the PageRank of E and denoted by PR(E). The name "PageRank" is a trademark of Google, and the PageRank process has been patented (U.S. Patent 6,285,999 ). However, the patent is assigned to Stanford University and not to Google. Google has exclusive license rights on the patent from Stanford University. The university received 1.8 million shares in Google in exchange for use of the patent; the shares were sold in 2005 for $336 million. Google describes PageRank: “ PageRank relies on the uniquely democratic nature of the web by using its vast link structure as an indicator of an individual pages value. In essence, Google interprets a link from page A to page B as a vote, by page A, for page B. But, Google looks at more than the sheer volume of votes, or links a page receives; it also analyzes the page that casts the vote. Votes cast by pages that are themselves "important" weigh more heavily and help to make other pages "important".” In other words, a PageRank results from a "ballot" among all the other pages on the World Wide Web about how important a page is. A hyperlink to a page counts as a vote of support. The PageRank of a page is defined recursively and depends on the number and PageRank metric of all pages that link to it ("incoming links"). A page that is linked to by many pages with high PageRank receives a high rank itself. If there are no links to a web page there is no support for that page. Google assigns a numeric weighting from 0-10 for each webpage on the Internet; this PageRank denotes a site’s importance in the eyes of Google. The PageRank is derived from a theoretical probability value on a logarithmic scale like the Richter Scale. The PageRank of a particular page is roughly based upon the quantity of inbound links as well as the PageRank of the pages providing the links. It is known that other factors, e.g. relevance of search words on the page and actual visits to the page reported by the Google toolbar also influence the PageRank. In order to prevent manipulation, spoofing and Spamdexing, Google provides no specific details about how other factors influence PageRank. Numerous academic papers concerning PageRank have been published since Page and Brins original paper. In practice, the PageRank concept has proven to be vulnerable to manipulation, and extensive research has been devoted to identifying falsely inflated PageRank and ways to ignore links from documents with falsely inflated PageRank. Other link-based ranking algorithms for Web pages include the HITS algorithm invented by Jon Kleinberg (used by Teoma and now Ask.com), the IBM CLEVER project, and the TrustRank algorithm.'
#%%
#Plagiarism- TASK C
c_1='Vector space model is an algebraic model for representing text documents (and in general, any objects) as vectors of identifiers, such as, for example, index terms. Its first use was in the SMART Information Retrieval System. It is used in information filtering, information retrieval, indexing and relevancy rankings. A document is represented as a vector, and each dimension corresponds to a separate term. If a term occurs in the document, its value in the vector is non-zero. Several different ways of computing these values, also known as (term) weights, have been developed. The definition of term depends on the application. Typically terms are single words, keywords, or longer phrases. If the words are chosen to be the terms, the dimensionality of the vector is the number of words in the vocabulary (the number of distinct words occurring in the corpus). One of the best known schemes is tf-idf weighting, proposed by Salton, Wong and Yang. In the classic vector space model, the term specific weights in the document vectors are products of local and global parameters. Relevancy rankings of documents in a keyword search can be calculated, using the assumptions of document similarities theory, by comparing the deviation of angles between each document vector and the original query vector where the query is represented as same kind of vector as the documents. The vector space model has the following imitations: * Search keywords must precisely match document terms; word substrings might result in a "false positive match"; * Semantic sensitivity; documents with similar context but different term vocabulary wont be associated, resulting in a "false negative match";  * The order in which the terms appear in the document is lost in the vector space representation; * Long documents are poorly represented because they have poor similarity values (a small scalar product and a large dimensionality).'
c_2='nformation retrieval (IR) is the science of searching for documents, for information within documents and for metadata about documents, as well as that of searching relational databases and the World Wide Web. IR is interdisciplinary, based on computer science, mathematics, library science, information science, information architecture, cognitive psychology, linguistics, statistics and physics. There is overlap in the usage of the terms data retrieval, document retrieval, information retrieval, and text retrieval, but each also has its own body of literature, theory, praxis and technologies. Automated information retrieval systems are used to reduce what has been called "information overload". Many universities and public libraries use IR systems to provide access to books, journals and other documents. '
c_3='The definition of term depends on the application. Typically terms are single words, keywords, or longer phrases. If the words are chosen to be the terms, the dimensionality of the vector is the number of words in the vocabulary A document is represented as a vector. Each dimensions corresponds to a separate terms. If a term occurs in the document, its value in the vector is non-zero. Relevancy rankings of documents in a keyword search can be calculated, using the assumptions of document similarities theory, by comparing the deviation of angles between each document vector and the original query vector where the query is represented as same kind of vector as the documents. LIMITATION: There is some limitation of vector space model. Models based on and extending the vector space model include: •	Generalized vector space model. (enhanced) Topic-based Vector Space Model [1] (eTVSM) — Extends the vector space model by removing the constraint that the term-vectors be orthogonal. In contrast to the generalized vector space model the (enhanced) Topic-based Vector Space Model does not depend on concurrence- based similarities between terms. The enhancement of the enhanced Topic-based Vector Space Model  (compared to the not enhanced one) is a proposal on how to derive term-vectors from an Ontology.'
c='Vector space model (or term vector model) is an algebraic model for representing text documents (and any objects, in general) as vectors of identifiers, such as, for example, index terms. It is used in information filtering, information retrieval, indexing and relevancy rankings. Its first use was in the SMART Information Retrieval System. A document is represented as a vector. Each dimension corresponds to a separate term. If a term occurs in the document, its value in the vector is non-zero. Several different ways of computing these values, also known as (term) weights, have been developed. One of the best known schemes is tf-idf weighting (see the example below). The definition of term depends on the application. Typically terms are single words, keywords, or longer phrases. If the words are chosen to be the terms, the dimensionality of the vector is the number of words in the vocabulary (the number of distinct words occurring in the corpus). The vector space model has the following limitations:    1. Long documents are poorly represented because they have poor similarity values (a small scalar product and a large dimensionality)    2. Search keywords must precisely match document terms; word substrings might result in a "false positive match"    3. Semantic sensitivity; documents with similar context but different term vocabulary wont be associated, resulting in a "false negative match". 4. The order in which the terms appear in the document is lost in the vector space representation.'

#%%
# Plagiarism- TASK D
d_1='In probability theory; Bayes theorem (often called Bayes law after RevThomas Bayes) relates the conditional and marginal probabilities of two random events. It is used to compute posterior probabilities given observations. For example; a person may be observed to have certain symptoms. Bayes theorem can be used to compute the probability that a proposed diagnosis is correct. As a formal theorem Bayes theorem is valid in all common interpretations of probability. However, it plays a central role in the debate around the foundations of statistics: frequentist and Bayesian interpretations disagree about the ways in which probabilities should be assigned to each other. Bayesians describe probabilities in terms of beliefs and degrees of uncertainty, While frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole. The articles on Bayesian probability and frequentist probability discuss these debates in detail.'
d_2='Bayes theorem relates the conditional and marginal probabilities of two random events and is named after the Reverend Thomas Bayes (1702–1761), who studied how to compute a distribution for the parameter of a binomial distribution. It is valid in all common interpretations of probability. It plays a central role in the debate around the foundations of statistics: frequentist and Bayesian interpretations disagree about the ways in which probabilities should be assigned in applications. Frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole, while Bayesians describe probabilities in terms of beliefs and degrees of uncertainty. Applications of Bayes theorem often assume the philosophy underlying Bayesian probability that uncertainty and degrees of belief can be measured as probabilities. One of Bayes results (Proposition 5) gives a simple description of conditional probability, and shows that it can be expressed independently of the order in which things occur: If there be two subsequent events, the probability of the second b/N and the probability of both together P/N, and it being first discovered that the second event has also happened, from hence I guess that the first event has also happened, the probability I am right [i.e., the conditional probability of the first event being true given that the second has also happened] is P/b. Note that the expression says nothing about the order in which the events occurred; it measures correlation, not causation.'
d_3=' In probability theory, Bayes theorem (often called Bayes law after Rev Thomas Bayes) relates the conditional and marginal probabilities of two random events. It is often used to compute posterior probabilities given observations. For example, a patient may be observed to have certain symptoms. Bayes theorem can be used to compute the probability that a proposed diagnosis is correct, given that observation. As a formal theorem, Bayes theorem is valid in all common interpretations of probability. However, it plays a central role in the debate around the foundations of statistics: frequentist and Bayesian interpretations disagree about the ways in which probabilities should be assigned in applications. Suppose there is a co-ed school having 60% boys and 40% girls as students. The girl students wear trousers or skirts in equal numbers; the boys all wear trousers. An observer sees a (random) student from a distance; all they can see is that this student is wearing trousers. What is the probability this student is a girl? The correct answer can be computed using Bayes theorem. The event A is that the student observed is a girl, and the event B is that the student observed is wearing trousers. To compute P(A|B), we first need to know: P(B|A), or the probability of the student wearing trousers given that the student is a boy. This is given as 1. P(A), or the probability that the student is a girl regardless of any other information. Since the observers sees a random student, meaning that all students have the same probability of being observed, and the fraction of girls among the students is 40%, this probability equals 0.4. P(A), or the probability that the student is a boy regardless of any other information (A is the complementary event to A). This is 60%, or 0.6. P(B|A), or the probability of the student wearing trousers given that the student is a girl. As they are as likely to wear skirts as trousers, this is 0.5. '
d_4='In probability theory, Bayes theorem (often called Bayes law after Rev Thomas Bayes) relates the conditional and marginal probabilities of two random events. It is often used to compute posterior probabilities given observations (for example, a patient may be observed to have certain symptoms). Bayes theorem can be used to compute the probability that a proposed diagnosis is correct, given that observation. As a formal theorem, Bayes theorem is valid in all common interpretations of probability. However, it plays a central role in the debate around the foundations of statistics; frequentist and Bayesian interpretations disagree about the ways in which probabilities should be assigned in applications. Frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole, while Bayesians describe probabilities in terms of beliefs and degrees of uncertainty. The articles on Bayesian probability and frequentist probability discuss these debates in greater detail. Bayes theorem relates the conditional and marginal probabilities of events A and B, where B has a non-vanishing probability: P(A|B) = (P(B | A) x P(A)) / P(B). Each term in Bayes theorem has a conventional name: P(A) is the prior probability or marginal probability of A. It is "prior" in the sense that it does not take into account any information about B. P(A|B) is the conditional probability of A, given B. It is also called the posterior probability because it is derived from or depends upon the specified value of B. P(B|A) is the conditional probability of B given A. P(B) is the prior or marginal probability of B, and acts as a normalizing constant. Intuitively, Bayes theorem in this form describes the way in which ones beliefs about observing A are updated by having observed B.'
d='In probability theory, Bayes theorem (often called Bayes law after Rev Thomas Bayes) relates the conditional and marginal probabilities of two random events. It is often used to compute posterior probabilities given observations. For example, a patient may be observed to have certain symptoms. Bayes theorem can be used to compute the probability that a proposed diagnosis is correct, given that observation. (See example 2) As a formal theorem, Bayes theorem is valid in all common interpretations of probability. However, it plays a central role in the debate around the foundations of statistics: frequentist and Bayesian interpretations disagree about the ways in which probabilities should be assigned in applications. Frequentists assign probabilities to random events according to their frequencies of occurrence or to subsets of populations as proportions of the whole, while Bayesians describe probabilities in terms of beliefs and degrees of uncertainty. The articles on Bayesian probability and frequentist probability discuss these debates in greater detail. Bayes theorem relates the conditional and marginal probabilities of events A and B, where B has a non-vanishing probability: P(A|B) = \frac{P(B | A)\, P(A)}{P(B)}. Each term in Bayes theorem has a conventional name: * P(A) is the prior probability or marginal probability of A. It is "prior" in the sense that it does not take into account any information about B. * P(A|B) is the conditional probability of A, given B. It is also called the posterior probability because it is derived from or depends upon the specified value of B. * P(B|A) is the conditional probability of B given A. * P(B) is the prior or marginal probability of B, and acts as a normalizing constant. Intuitively, Bayes theorem in this form describes the way in which ones beliefs about observing A are updated by having observed B.'

#%%
# Plagiarism- TASK E
e_1='dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure (described below). The method takes much less time than naive methods. The word "programming" in "dynamic programming" has no particular connection to computer programming at all, and instead comes from the term "mathematical programming", a synonym for optimization. Thus, the "program" is the optimal plan for action that is produced. For instance, a finalized schedule of events at an exhibition is sometimes called a program. Programming, in this sense, means finding an acceptable plan of action, an algorithm.'
e_2='In mathematics and computer science, dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure. The word "programming" in "dynamic programming" has no particular connection to computer programming at all, and instead comes from the term "mathematical programming", a synonym for optimization. Programming, in this sense, means finding an acceptable plan of action, an algorithm. Optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem. In general, we can solve a problem with optimal substructure using a three-step process: 1. Break the problem into smaller subproblems. 2. Solve these problems optimally using this three-step process recursively. 3. Use these optimal solutions to construct an optimal solution for the original problem. The subproblems are, themselves, solved by dividing them into sub-subproblems, and so on, until we reach some simple case that is solvable in constant time. To say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems. For example, in the Fibonacci sequence, F3 = F1 + F2 and F4 = F2 + F3 — computing each number involves computing F2. Because both F3 and F4 are needed to compute F5, a naive approach to computing F5 may end up computing F2 twice or more. This applies whenever overlapping subproblems are present: a naive approach may waste time recomputing optimal solutions to subproblems it has already solved. In order to avoid this, we instead save the solutions to problems we have already solved. Then, if we need to solve the same problem later, we can retrieve and reuse our already-computed solution. If we are sure we wont need a particular solution anymore, we can throw it away to save space. In some cases, we can even compute the solutions to subproblems we know that well need in advance. dynamic programming makes use of: Overlapping subproblems   Optimal substructure    Memoization .Dynamic programming usually takes one of two approaches: Top-down approach  Bottom-up approach'
e_3='In mathematics and computer science, dynamic programming is a method of solving problems that exhibit the properties of overlapping sub problems and optimal substructure. The term was originally used in the 1940s by Richard Bellman to describe the process of solving problems where one needs to find the best decisions one after another. By 1953, he had refined this to the modern meaning. Bellmans contribution is remembered in the name of the Bellman equation, a central result of dynamic programming which restates an optimization problem in recursive form. The word "programming" in "dynamic programming" has no particular connection to computer programming at all, and instead comes from the term "mathematical programming", a synonym for optimization. Thus, the "program" is the optimal plan for action that is produced. For instance, a finalized schedule of events at an exhibition is sometimes called a program. Programming, in this sense, means finding an acceptable plan of action, an algorithm. Dynamic programming usually takes one of two approaches, the top-down approach, the problem is broken into sub problems, and these sub problems are solved and the solutions remembered, in case they need to be solved again. This is recursion and memorization combined together and the bottom-up approach, all sub problems that might be needed are solved in advance and then used to build up solutions to larger problems. This approach is slightly better in stack space and number of function calls, but it is sometimes not intuitive to figure out all the sub problems needed for solving the given problem. Some programming languages can automatically memorize the result of a function call with a particular set of arguments, in order to speed up call-by-name. Some languages make it possible portably (e.g. Scheme, Common Lisp or Perl), some need special extensions.This is only possible for a referentially transparent function.'
e_4='In mathematics and computer science, dynamic programming is a method of solving problems, that exhibit the properties of overlapping subproblems and optimal substructure. The method takes much less time than naive methods. The term was originally used in the 1940s to describe the process of solving problems where one needs to find the best decisions one after another. The field was founded as a systems analysis and engineering topic that is recognized by the IEEE. The word "programming" in "dynamic programming" has no particular connection to computer programming at all, and instead comes from the term "mathematical programming", a synonym for optimization. Thus, the "program" is the optimal plan for action that is produced. For instance, a finalized schedule of events at an exhibition is sometimes called a program. Programming, in this sense, means finding an acceptable plan of action, an algorithm. Optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem. For example, the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices, and then using this to pick the best overall path. In general, we can solve a problem with optimal substructure using a three-step process: 1.Break the problem into smaller subproblems. 2.solve these problems optimally using this three-step process recursively. 3.Use these optimal solutions to construct an optimal solution for the original problem. The subproblems are, themselves, solved by dividing them into sub-subproblems, and so on, until we reach some simple case that is solvable in constant time.'
e_5='Dynamic Programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure.  The term was originally used in the 1940s by Richard Bellman. The word "programming" in "dynamic programming" has no particular connection to computer programming at all, and instead comes from the term "mathematical programming", a synonym for optimization.  The "program" is the optimal plan for action that is produced. For instance, a finalized schedule of events at an exhibition is sometimes called a program. Programming, in this sense, means finding an acceptable plan of action. To say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems.  Optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem.'
#e_aux='In the field of computer science, term dynamic programming relates to the style of programming that breaks a large problem down into smaller subproblems, and generally allows for the finding of the optimal solution. When the problem is split into subproblems, these themselves may be split into smaller problems, and so on, until they cannot be reduced any more. It is also common for dynamic programming to make use of recursion, and the saving of previous results for faster computation later; this also leads to higher efficiency, as calculations are not being redone. For example, when a problem is reduced into sub problems, and those are then reduced further, it may be that there are common subsubproblems, and so only one calculation needs to be done and the result saved to help solve more than one subproblem. An example of this gain in efficiency is a path-finding problem. If there are two distinct routes in a network of 10 nodes, tagged A to J, then if the two routes share a common section (say, between nodes B and D), the cost of that section should be calculated for the first route and saved. Then, when the second route is being processed, the cost of B to D does not need to be calculated again. In general, dynamic programming is used on optimisation problems, where the most efficient solution is needed. Areas where this sort of programming is useful is in AI, computer graphics, compression routines, and biomedical applications.'
e='In mathematics and computer science, dynamic programming is a method of solving problems that exhibit the properties of overlapping subproblems and optimal substructure (described below). The method takes much less time than naive methods. The term was originally used in the 1940s by Richard Bellman to describe the process of solving problems where one needs to find the best decisions one after another. By 1953, he had refined this to the modern meaning. The field was founded as a systems analysis and engineering topic that is recognized by the IEEE. Bellmans contribution is remembered in the name of the Bellman equation, a central result of dynamic programming which restates an optimization problem in recursive form. The word "programming" in "dynamic programming" has no particular connection to computer programming at all, and instead comes from the term "mathematical programming", a synonym for optimization. Thus, the "program" is the optimal plan for action that is produced. For instance, a finalized schedule of events at an exhibition is sometimes called a program. Programming, in this sense, means finding an acceptable plan of action, an algorithm. Optimal substructure means that optimal solutions of subproblems can be used to find the optimal solutions of the overall problem. For example, the shortest path to a goal from a vertex in a graph can be found by first computing the shortest path to the goal from all adjacent vertices, and then using this to pick the best overall path, as shown in Figure 1. In general, we can solve a problem with optimal substructure using a three-step process: 1. Break the problem into smaller subproblems. 2. Solve these problems optimally using this three-step process recursively. 3. Use these optimal solutions to construct an optimal solution for the original problem. The subproblems are, themselves, solved by dividing them into sub-subproblems, and so on, until we reach some simple case that is solvable in constant time. Figure 2. The subproblem graph for the Fibonacci sequence. That it is not a tree but a DAG indicates overlapping subproblems. To say that a problem has overlapping subproblems is to say that the same subproblems are used to solve many different larger problems. For example, in the Fibonacci sequence, F3 = F1 + F2 and F4 = F2 + F3 — computing each number involves computing F2. Because both F3 and F4 are needed to compute F5, a naive approach to computing F5 may end up computing F2 twice or more. This applies whenever overlapping subproblems are present: a naive approach may waste time recomputing optimal solutions to subproblems it has already solved. In order to avoid this, we instead save the solutions to problems we have already solved. Then, if we need to solve the same problem later, we can retrieve and reuse our already-computed solution. This approach is called memoization (not memorization, although this term also fits). If we are sure we wont need a particular solution anymore, we can throw it away to save space. In some cases, we can even compute the solutions to subproblems we know that well need in advance.'


#%%
"""summary_1=summary(inst_1)
summary_1_words,summary_1_vocab=stemming(summary_1,10)
summary_1_tfidf_1=TFIDF(summary_1)
words_1,vocab_1=stemming(inst_1,10)        
trigram_1,bigram_1=ngram(vocab_1)

summary_2=summary(inst_2)
summary_2_words,summary_2_vocab=stemming(summary_2,10)
summary_2_tfidf=TFIDF(summary_2)
words_2,vocab_2=stemming(inst_2,10)        
trigram_2,bigram_2=ngram(vocab_2)

summary_3=summary(inst_3)
summary_3_words,summary_3_vocab=stemming(summary_3,10)
summary_3_tfidf=TFIDF(summary_3)
words_3,vocab_3=stemming(inst_3,10)        
trigram_3,bigram_3=ngram(vocab_3)

summary_4=summary(inst_4)
summary_4_words,summary_4_vocab=stemming(summary_4,10)
summary_4_tfidf=TFIDF(summary_4)
words_4,vocab_4=stemming(inst_4,10)        
trigram_4,bigram_4=ngram(vocab_4)

summary_5=summary(inst_5)
summary_5_words,summary_5_vocab=stemming(summary_5,10)
summary_5_tfidf=TFIDF(summary_5)
words_5,vocab_5=stemming(inst_5,10)        
trigram_5,bigram_5=ngram(vocab_5)

words_6,vocab_6=stemming(inst_6,10)        
summary_6=summary(inst_6)
summary_6_words,summary_6_vocab=stemming(summary_6,10)
summary_6_tfidf=TFIDF(summary_6)
trigram_6,bigram_6=ngram(vocab_6)


words_7,vocab_7=stemming(inst_7,10)        
summary_7=summary(inst_7)
summary_7_words,summary_7_vocab=stemming(summary_7,10)


words_8,vocab_8=stemming(inst_8,10)        
summary_8=summary(inst_8)
summary_8_words,summary_8_vocab=stemming(summary_8,10)


words_9,vocab_9=stemming(inst_9,10)        
summary_9=summary(inst_9)
summary_9_words,summary_9_vocab=stemming(summary_9,10)

words_10,vocab_10=stemming(inst_10,10)        
summary_10=summary(inst_10)
summary_10_words,summary_10_vocab=stemming(summary_10,10)

words_11,vocab_11=stemming(inst_11,10)        
summary_11=summary(inst_11)
summary_11_words,summary_11_vocab=stemming(summary_11,10)

words_12,vocab_12=stemming(inst_12,10)        
summary_12=summary(inst_12)
summary_12_words,summary_12_vocab=stemming(summary_12,10)

words_13,vocab_13=stemming(inst_13,10)   
summary_13=summary(inst_13)
summary_13_words,summary_13_vocab=stemming(summary_13,10)

words_14,vocab_14=stemming(inst_14,10)   
summary_14=summary(inst_14)
summary_14_words,summary_14_vocab=stemming(summary_14,10)

words_15,vocab_15=stemming(inst_15,10)   
summary_15=summary(inst_15)
summary_15_words,summary_15_vocab=stemming(summary_15,10)

words_16,vocab_16=stemming(inst_16,10)   
summary_16=summary(inst_16)
summary_16_words,summary_16_vocab=stemming(summary_16,10)

words_17,vocab_17=stemming(inst_17,10)   
summary_17=summary(inst_17)
summary_17_words,summary_17_vocab=stemming(summary_17,10)

words_18,vocab_18=stemming(inst_18,10)   
summary_18=summary(inst_18)
summary_18_words,summary_18_vocab=stemming(summary_18,10)

words_19,vocab_19=stemming(inst_19,10)   
summary_19=summary(inst_19)
summary_19_words,summary_19_vocab=stemming(summary_19,10)

words_orig,vocab_orig=stemming(orig,10)   
summary_orig=summary(orig)
summary_orig_words,summary_orig_vocab=stemming(summary_orig,10)
trigram_orig,bigram_orig=ngram(vocab_orig)
summary_orig_tfidf=TFIDF(summary_orig)"""

#%% 
obs_word=pd.DataFrame([words_1,words_2,words_3,words_4,words_5,words_6,words_7,words_8,words_9,words_10,words_11,words_12,words_13,words_14,words_15,words_16,words_17,words_18,words_19,words_orig])
obs_summary_word=pd.DataFrame([summary_1_words,summary_2_words,summary_3_words,summary_4_words,summary_5_words,summary_6_words,summary_7_words,summary_8_words,summary_9_words,summary_10_words,summary_11_words,summary_12_words,summary_13_words,summary_14_words,summary_15_words,summary_16_words,summary_17_words,summary_18_words,summary_19_words,summary_orig_words])

#%%
# EXACT COPY evaluation:
#A
val_1=plgcpy(inst_6,orig)
val_2=plgcpy(inst_12,orig)
val_3=plgcpy(inst_13,orig)
val_4=plgcpy(inst_17, orig)

#B
val_5=plgcpy(b_1,b)
val_6=plgcpy(b_2,b)
val_7=plgcpy(b_3,b)  # outlier 

#C
val_8=plgcpy(c_1,c)
val_9=plgcpy(c_3,c) #----> number of word matches in doc=10 

#D
val_10=plgcpy(d_1,d) #----> 7 bigram matches 
val_11=plgcpy(d_2,d)
val_12=plgcpy(d_3,d) # wrong  after cleaning cosine similarity decreased = 0.16 
val_13=plgcpy(d_4,d) 

#E
val_14=plgcpy(e_1,e) # ----> number of word matches in doc=8  due to short length of document.
val_15=plgcpy(e_2, e)
val_16=plgcpy(e_3, e) 
val_17=plgcpy(e_4, e)
val_18=plgcpy(e_5, e) 
#plgcpy(e_aux,e)

#%%
#Analysis
df=pd.DataFrame([val_1,val_2,val_3,val_4,val_5,val_6,val_7,val_8,val_9,val_10,val_11,val_12,val_13,val_14,val_15,val_16,val_17,val_18],columns=['Bigram Matches','Words match in doc','Words match in summary','Similarity Score'])
x=df.iloc[:,0].values
y=df.iloc[:,1].values
z=df.iloc[:,2].values
w=df.iloc[:,-1].values
p=[i for i in range(18)]
plt.scatter(p,x,color='red',marker='*')
plt.scatter(p,y,color='blue',marker='s')
plt.title('Doc Word matches and bigram')
plt.legend(['Bigram', 'word-Doc'])
plt.xlabel('document index')
plt.ylabel('Number of matches')
plt.show()
plt.scatter(p,z,color='green',marker='o')
plt.title('Word Matches in summary')
plt.xlabel('document index')
plt.ylabel('Number of matches')
plt.show()
plt.scatter(p,w,color='black',marker='1')
plt.title('Similarity scores')
plt.xlabel('document index')
plt.ylabel('Similarity score')
plt.show()


"""
# Min values:
Bigram Matches            7.000000
Words match in doc        8.000000
Words match in summary    2.000000
Similarity Score          0.162851
dtype: float64

#Average Values:
Bigram Matches            16.555556
Words match in doc        19.166667
Words match in summary     5.611111
Similarity Score           0.649270
dtype: float64

"""
#%%
#calculate accuracy
acc=[val_1,val_2,val_3,val_4,val_5,val_6,val_7,val_8,val_9,val_10,val_11,val_12,val_13,val_14,val_15,val_16,val_17,val_18]
accuracy=(acc.count('Plagiarised')/len(acc))*100
print(accuracy)




